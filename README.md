# 概要
---
#### Prototypical Networks for Few-shot Learning
- **Jake Snell**, University of Toronto
- **Kevin Swersky**, Twitter
- **Richard S. Zemel**, University of Toronto, Vector Institute

**概要:**
- Few-shot分類の問題に対するプロトタイプネットワークの提案
- クラスごとのプロトタイプ表現に基づく分類
- アーキテクチャのシンプルさとメタ学習で優れた帰納バイアスを獲得

---

# プロトタイプネットワークの基本概念
---
**プロトタイプネットワーク:**
- 各クラスのプロトタイプ表現を用いて分類
- シンプルな帰納バイアスとメタ学習で汎化性能を獲得

**基本アイデア:**
- 各クラスのプロトタイプ \( c_k \) をサポートポイントの平均として計算
- クエリポイントの埋め込みと各プロトタイプ間の距離を計算

---

# スライド5: モデルの数式
---
**プロトタイプ計算:**
\[ c_k = \frac{1}{|S_k|} \sum_{(x_i, y_i) \in S_k} f_\phi(x_i) \]

**クラス分布の計算:**
\[ p_\phi(y = k | x) = \frac{\exp(-d(f_\phi(x), c_k))}{\sum_{k'} \exp(-d(f_\phi(x), c_{k'}))} \]

**損失関数:**
\[ J(\phi) = - \log p_\phi(y = k | x) \]

**用語:**
- **Embedding Function** \( f_\phi \): 入力を埋め込み空間にマッピングする関数
- **Prototype** \( c_k \): 各クラスのプロトタイプ表現
- **Distance Function** \( d \): 埋め込み空間内の距離を計算する関数

---

# メタ学習のフレームワーク
---
**メタ学習:**
- **タスク（エピソード）**: 特定のクラスとそのサンプルから構成される学習ユニット
- **サポートセット**: 各タスク内でモデルが学習するためのラベル付きデータ
- **クエリセット**: 各タスク内でモデルの性能を評価するためのラベル付きデータ
- **ベース学習（インナーループ）**: 各タスク内での学習
- **メタ学習（アウターループ）**: 複数のタスクを通じてモデル全体のパラメータを最適化

**タスクのサンプリング:**
- エピソードごとに異なるクラスインデックスを選択し、タスクをサンプリング

**損失関数の共通性:**
- 全てのエピソードが分類タスクであり、共通の損失関数を使用

**目的:**
- モデルが多様なタスクに対して迅速に適応する能力を学習

---

# トレーニングエピソードのアルゴリズム
---
**アルゴリズム1: トレーニングエピソードの損失計算**

1. **クラスインデックス \( V \) をエピソード用に選択**
   - \( V \leftarrow \text{RANDOMSAMPLE}(\{1, \ldots, K\}, N_C) \)
2. **サポートセットとクエリセットの構築**
   - 各クラス \( k \) に対して:
     - サポートセット \( S_k \) をランダムに選択
     - クエリセット \( Q_k \) をランダムに選択
     - サポートセットからプロトタイプ \( c_k \) を計算
3. **損失の初期化**
   - \( J \leftarrow 0 \)
4. **損失の更新**
   - 各クラス \( k \) に対して:
     - クエリポイントに対して損失 \( J \) を更新

**疑似コード:**
```plaintext
Input: Training set D = {(x1, y1), ..., (xN, yN)}, where each yi ∈ {1, ..., K}.
V ← RANDOMSAMPLE({1, ..., K}, NC)  # Select class indices for episode
for k in {1, ..., NC } do
    Sk ← RANDOMSAMPLE(DVk, NS)  # Select support examples
    Qk ← RANDOMSAMPLE(DVk \ Sk, NQ)  # Select query examples
    ck ← (1/|Sk|) ∑_{(xi, yi) ∈ Sk} fφ(xi)  # Compute prototype from support examples
end for
J ← 0  # Initialize loss
for k in {1, ..., NC } do
    for (x, y) in Qk do
        J ← J + (1/(NC * NQ)) [d(fφ(x), prototypes[k]) + log ∑_{k'} exp(-d(fφ(x), prototypes[k']))]
    end for
end for
```



# スライド8: プロトタイプネットワークとしての混合密度推定
---
**混合密度推定としてのプロトタイプネットワーク**:
- 特定の距離関数（Bregmanダイバージェンス）を使用する場合、プロトタイプネットワークアルゴリズムは指数型分布を持つサポートセット上での混合密度推定と等価。

**Bregmanダイバージェンス**:
\[ d_\phi(z, z') = \phi(z) - \phi(z') - (z - z')^\top \nabla \phi(z') \]
ここで、 \( \phi \) は微分可能で、Legendre型の厳密に凸な関数。

**プロトタイプ計算の再解釈**:
- Bregmanダイバージェンスの場合、クラスター代表点はクラスターの平均であり、プロトタイプ計算はサポートセットラベルに基づく最適なクラスター代表点を提供。

**指数型分布とBregmanダイバージェンス**:
\[ p_\psi(z|\theta) = \exp\{z^\top \theta - \psi(\theta) - g_\psi(z)\} = \exp\{-d_\phi(z, \mu(\theta)) - g_\phi(z)\} \]

**混合モデルとクラスター割り当て**:
\[ p(z|\Γ) = \sum_{k=1}^{K} \pi_k \exp(-d_\phi(z, \mu(\θ_k)) - g_\phi(z)) \]
\[ p(y = k | z) = \frac{\pi_k \exp(-d_\φ(z, \mu(\θ_k)))}{\sum_{k'} \pi_{k'} \exp(-d_\φ(z, \mu(\θ_{k'})))} \]

**リマーク**:
- 距離の選択は、埋め込み空間内のクラス条件付きデータ分布のモデリング仮定を指定。

---

# スライド9: 線形モデルとしての再解釈
---
**数式の再解釈:**
- ユークリッド距離の展開:
\[ -\| f_\φ(x) - c_k \|^2 = -f_\φ(x)^\top f_\φ(x) + 2c_k^\top f_\φ(x) - c_k^\top c_k \]

- 線形モデルの形:
\[ 2c_k^\top f_\φ(x) - c_k^\top c_k = w_k^\top f_\φ(x) + b_k \]
\[ w_k = 2c_k, \quad b_k = -c_k^\top c_k \]

**リマーク:**
- 非線形性は埋め込み関数内で学習可能
- 埋め込み関数 \( f_\φ \) は、データを線形分離可能な特徴空間にマッピング

---

# スライド10: データセット
---
**使用されるデータセット:**
1. **Omniglot**:
   - 手書き文字データセット
   - 1623文字、各文字20例
   - データ拡張（90度ごとの回転）
   - 少数ショット学習の評価（1ショット、5ショット）

2. **miniImageNet**:
   - カラー画像データセット
   - 100クラス、各クラス600例
   - データセット分割（訓練: 64クラス、検証: 16クラス、テスト: 20クラス）
   - 少数ショット学習の評価（1ショット、5ショット）

3. **CUB-200-2011**:
   - 鳥種データセット
   - 200種類、11,788枚の画像
   - クラス属性ベクトル（312次元）
   - ゼロショット学習の評価

**目的:**
- 異なるドメインのタスクでモデルの汎化性能を評価
- 少数ショットおよびゼロショット学習の性能を評価

---

# スライド11: Omniglot少数ショット分類
---
**Omniglotデータセット:**
- 1623文字、各文字に20例（異なる人間による手書き）
- グレースケール画像を28×28にリサイズし、90度ごとの回転で拡張

**エンコーディングアーキテクチャ:**
- 4つの畳み込みブロック: 各ブロックは64フィルターの3×3畳み込み、バッチ正規化、ReLU、2×2のマックスプーリング
- 出力次元: 64次元

**トレーニング手法:**
- 学習率: 初期値10−3、2000エピソードごとに半減
- 正規化: バッチ正規化のみ

**結果:**
- 1ショットおよび5ショットシナリオでユークリッド距離を使用
- 他の手法（Neural Statistician, Matching Networks）と比較し、優れた性能を発揮

---

# スライド12: Omniglotの結果
---
**Omniglotデータセットの分類精度:**

| モデル | 距離 | Fine Tune | 1ショット | 5ショット |
|---|---|---|---|---|
| MATCHING NETWORKS [29] | コサイン | N | 98.1% | 98.9% |
| MATCHING NETWORKS [29] | コサイン | Y | 97.9% | 98.7% |
| NEURAL STATISTICIAN [6] | - | N | 98.1% | 99.5% |
| PROTOTYPICAL NETWORKS (OURS) | ユークリッド | N | 98.8% | 99.7% |

---

# スライド13: miniImageNet少数ショット分類
---
**miniImageNetデータセット:**
- ILSVRC-12データセットから派生
- 60,000枚のカラー画像（84×84）、100クラス、各クラス600例
- 訓練: 64クラス、検証: 16クラス、テスト: 20クラス

**エンコーディングアーキテクチャ:**
- Omniglotと同様の4ブロック構造、出力次元: 1600次元

**トレーニング手法:**
- 学習率: Omniglotと同じ
- トレーニングエピソード: 1ショットは30-way、5ショットは20-way

**結果:**
- 他の手法（Nearest Neighbors, Matching Networks, Meta-Learner LSTM）と比較し、プロトタイプネットワークが最先端の性能を発揮

---

# スライド14: miniImageNetの結果
---
**miniImageNetデータセットの分類精度:**

| モデル | 距離 | Fine Tune | 1ショット | 5ショット |
|---|---|---|---|---|
| BASELINE NEAREST NEIGHBORS [22] | コサイン | N | 28.86 ± 0.54% | 49.79 ± 0.79% |
| MATCHING NETWORKS [29] | コサイン | N | 43.40 ± 0.78% | 51.09 ± 0.71% |
| MATCHING NETWORKS FCE [29] | コサイン | N | 43.56 ± 0.84% | 55.31 ± 0.73% |
| META-LEARNER LSTM [22] | - | N | 43.44 ± 0.77% | 60.60 ± 0.71% |
| PROTOTYPICAL NETWORKS (OURS) | ユークリッド | N | 49.42 ± 0.78% | 68.20 ± 0.66% |

---

# スライド15: miniImageNetの詳細解析
---
**比較: 距離メトリックとトレーニングエピソードのクラス数**

- 図2: 1ショットおよび5ショットシナリオにおける5-way分類精度
- ユークリッド距離がコサイン距離よりも性能向上
- 20-wayのトレーニングエピソードがより高い精度を達成

**リマーク:**
- 20-wayの分類は、埋め込み空間での微細な決定を促進し、汎化能力を向上

---

# スライド16: CUB-200ゼロショット分類
---
**CUB-200-2011データセット:**
- 200種の鳥、11,788枚の画像
- データ準備: Reed et al. [23] の手順に従う

**エンコーディングアーキテクチャ:**
- 1,024次元の画像特徴量（GoogLeNetを使用）
- 312次元のクラス属性ベクトル

**トレーニング手法:**
- 50クラスのトレーニングエピソード、各クラス10のクエリ画像
- 学習率: 10−4、ウェイト減衰: 10−5

**結果:**
- 他の手法（ALE, SJE, DS-SJE, DA-SJE）と比較し、プロトタイプネットワークが最先端の性能を発揮

---

# スライド17: CUB-200の結果
---
**CUB-200データセットのゼロショット分類精度:**

| モデル | 画像特徴量 | 50-way 0ショット精度 |
|---|---|---|
| ALE [1] | Fisher | 26.9% |
| SJE [2] | AlexNet | 40.3% |
| SAMPLE CLUSTERING [17] | AlexNet | 44.3% |
| SJE [2] | GoogLeNet | 50.1% |
| DS-SJE [23] | GoogLeNet | 50.4% |
| DA-SJE [23] | GoogLeNet | 50.9% |
| PROTOTYPICAL NETWORKS (OURS) | GoogLeNet | 54.6% |

---

# スライド18: 関連研究
---
**距離学習:**
- Neighborhood Components Analysis (NCA) [8]
- Large Margin Nearest Neighbor (LMNN) [30]
- DNet-KNN [21]

**少数ショット学習:**
- Meta-Learning Approach [22]
- Neural Statistician [6]

**ゼロショット学習:**
- Embedding Meta-Data [3]
- DS-SJE and DA-SJE [23]

**リマーク:**
- プロトタイプネットワークはシンプルでありながら効果的なアプローチ
- エピソディックトレーニングとBregmanダイバージェンスの利用が有望

---

# スライド19: 結論
---
**結論:**
- プロトタイプネットワークは少数ショットおよびゼロショット学習において有望なアプローチ
- シンプルな設計でありながら優れた性能を発揮

**将来の展望:**
- Bregmanダイバージェンスの利用拡大
- 埋め込みネットワークのさらなる改良と応用の可能性

**質疑応答**

---
